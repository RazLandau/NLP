Implementation of a [Neural Bigram language model](https://en.wikipedia.org/wiki/Language_model#Neural_network), with one [sigmoid](https://en.wikipedia.org/wiki/Sigmoid_function)
hidden layer using [GloVe word embeddings](https://en.wikipedia.org/wiki/GloVe_(machine_learning)) to represent the vocabulary and [SGD](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) for optimizations. 
