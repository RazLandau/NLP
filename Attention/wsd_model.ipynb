{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "colab": {
   "name": "Copy of wsd_model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Initialization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from IPython.core.display import display\n",
    "import data_loader\n",
    "import traineval\n",
    "import model as model\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "seed = 42\n",
    "\n",
    "pd.set_option('max_columns', 100)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"device used is {device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset, tokens_vocab, y_vocab = data_loader.load_train_dataset()\n",
    "dev_dataset = data_loader.load_dev_dataset(tokens_vocab, y_vocab)\n",
    "print(train_dataset, dev_dataset, sep='\\n')\n",
    "\n",
    "sa_train_dataset = data_loader.WSDSentencesDataset.from_word_dataset(train_dataset)\n",
    "sa_dev_dataset = data_loader.WSDSentencesDataset.from_word_dataset(dev_dataset)\n",
    "print(sa_train_dataset, sa_dev_dataset, sep='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 1: Query-Based Attention"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importlib.reload(model)\n",
    "\n",
    "dropout = 0.25\n",
    "D = 300\n",
    "lr = 8e-5\n",
    "batch_size = 100\n",
    "num_epochs = 5\n",
    "set_seed(seed)\n",
    "\n",
    "m1 = model.WSDModel(\n",
    "    tokens_vocab.size(),\n",
    "    y_vocab.size(),\n",
    "    D=D,\n",
    "    dropout_prob=dropout\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(m1.parameters(), lr=lr)\n",
    "\n",
    "losses1, train_acc1, val_acc1 = traineval.train(\n",
    "    m1, optimizer, train_dataset, dev_dataset, num_epochs=num_epochs, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Validation accuracy: {val_acc1[-1]:.3f}, Training accuracy:{train_acc1[-1]:.3f}\")\n",
    "assert round(val_acc1[-1],\n",
    "             3) >= 0.514, \"The last validation accuracy should be at least 0.514. Please check your implementation before you continue\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(nrows=2, figsize=(15, 6))\n",
    "\n",
    "axs[0].plot(losses1, '-', label='Train Loss')\n",
    "axs[0].legend()\n",
    "axs[1].plot(train_acc1, '-o', label='Train Acc')\n",
    "axs[1].plot(val_acc1, '-o', label='Val Acc')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "traineval.higlight_samples(m1, dev_dataset, sample_size=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_df, attention_df = traineval.evaluate_verbose(m1, dev_dataset, iter_lim=100)\n",
    "\n",
    "idxs = np.where(eval_df['y_true'] != eval_df['y_pred'])\n",
    "idxs = list(idxs[0][:5])\n",
    "display(traineval.highlight(eval_df, attention_df, idxs))\n",
    "\n",
    "idxs = np.where(eval_df['query_token'] == 'left')\n",
    "display(traineval.highlight(eval_df, attention_df, idxs))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 2: Padding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importlib.reload(model)\n",
    "\n",
    "dropout = 0.25\n",
    "D = 300\n",
    "lr = 8e-5\n",
    "batch_size = 100\n",
    "num_epochs = 5\n",
    "set_seed(seed)\n",
    "\n",
    "m2 = model.WSDModel(\n",
    "    tokens_vocab.size(),\n",
    "    y_vocab.size(),\n",
    "    D=D,\n",
    "    dropout_prob=dropout,\n",
    "    use_padding=True\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(m2.parameters(), lr=lr)\n",
    "\n",
    "losses2, train_acc2, val_acc2 = traineval.train(\n",
    "    m2, optimizer, train_dataset, dev_dataset, num_epochs=num_epochs, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Validation accuracy: {val_acc2[-1]:.3f}, Training accuracy:{train_acc2[-1]:.3f}\")\n",
    "assert round(val_acc2[-1],\n",
    "             3) >= 0.527, \"The last validation accuracy should be at least 0.527. Please check your implementation before you continue\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(nrows=2, figsize=(15, 6))\n",
    "\n",
    "axs[0].plot(losses2, '-', label='Train Loss')\n",
    "axs[0].legend()\n",
    "axs[1].plot(train_acc2, '-o', label='Train Acc')\n",
    "axs[1].plot(val_acc2, '-o', label='Val Acc')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "traineval.higlight_samples(m2, dev_dataset, sample_size=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_df, attention_df = traineval.evaluate_verbose(m2, dev_dataset, iter_lim=100)\n",
    "\n",
    "idxs = np.where(eval_df['y_true'] != eval_df['y_pred'])\n",
    "idxs = list(idxs[0][:5])\n",
    "display(traineval.highlight(eval_df, attention_df, idxs))\n",
    "\n",
    "idxs = np.where(eval_df['query_token'] == 'left')\n",
    "display(traineval.highlight(eval_df, attention_df, idxs))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 3: Self-Attention"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importlib.reload(model)\n",
    "\n",
    "lr = 2e-4\n",
    "dropout = 0.2\n",
    "D = 300\n",
    "batch_size = 20\n",
    "num_epochs = 5\n",
    "set_seed(seed)\n",
    "\n",
    "m3 = model.WSDModel(\n",
    "    tokens_vocab.size(),\n",
    "    y_vocab.size(),\n",
    "    D=D,\n",
    "    dropout_prob=dropout,\n",
    "    use_padding=True\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(m3.parameters(), lr=lr)\n",
    "\n",
    "losses3, train_acc3, val_acc3 = traineval.train(\n",
    "    m3, optimizer, sa_train_dataset, sa_dev_dataset, num_epochs=num_epochs, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Validation accuracy: {val_acc3[-1]:.3f}, Training accuracy:{train_acc3[-1]:.3f}\")\n",
    "assert val_acc3[\n",
    "           -1] >= 0.543, \"The last validation accuracy should be at least 0.543. Please check your implementation before you continue\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(nrows=2, figsize=(15, 6))\n",
    "\n",
    "axs[0].plot(losses3, '-', label='Train Loss')\n",
    "axs[0].legend()\n",
    "axs[1].plot(train_acc3, '-o', label='Train Acc')\n",
    "axs[1].plot(val_acc3, '-o', label='Val Acc')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "traineval.higlight_samples(m3, dev_dataset, sample_size=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_df, attention_df = traineval.evaluate_verbose(m3, dev_dataset, iter_lim=100)\n",
    "\n",
    "idxs = np.where(eval_df['y_true'] != eval_df['y_pred'])\n",
    "idxs = list(idxs[0][:5])\n",
    "display(traineval.highlight(eval_df, attention_df, idxs))\n",
    "\n",
    "idxs = np.where(eval_df['query_token'] == 'left')\n",
    "display(traineval.highlight(eval_df, attention_df, idxs))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 4: Positional embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importlib.reload(model)\n",
    "\n",
    "lr = 2e-4\n",
    "dropout = 0.2\n",
    "D = 300\n",
    "batch_size = 20\n",
    "num_epochs = 5\n",
    "set_seed(seed)\n",
    "\n",
    "m4 = model.WSDModel(\n",
    "    tokens_vocab.size(),\n",
    "    y_vocab.size(),\n",
    "    D=D,\n",
    "    dropout_prob=dropout,\n",
    "    use_padding=True,\n",
    "    use_positional=True\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(m4.parameters(), lr=lr)\n",
    "\n",
    "losses4, train_acc4, val_acc4 = traineval.train(\n",
    "    m4, optimizer, sa_train_dataset, sa_dev_dataset, num_epochs=num_epochs, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Validation accuracy: {val_acc4[-1]:.3f}, Training accuracy:{train_acc4[-1]:.3f}\")\n",
    "assert val_acc4[\n",
    "           -1] >= 0.543, \"The last validation accuracy should be at least 0.543. Please check your implementation before you continue\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(nrows=2, figsize=(15, 6))\n",
    "\n",
    "axs[0].plot(losses4, '-', label='Train Loss')\n",
    "axs[0].legend()\n",
    "axs[1].plot(train_acc4, '-o', label='Train Acc')\n",
    "axs[1].plot(val_acc4, '-o', label='Val Acc')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "traineval.higlight_samples(m4, sa_dev_dataset, sample_size=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_df, attention_df = traineval.evaluate_verbose(m4, dev_dataset, iter_lim=100)\n",
    "\n",
    "idxs = np.where(eval_df['y_true'] != eval_df['y_pred'])\n",
    "idxs = list(idxs[0][:5])\n",
    "display(traineval.highlight(eval_df, attention_df, idxs))\n",
    "\n",
    "idxs = np.where(eval_df['query_token'] == 'left')\n",
    "display(traineval.highlight(eval_df, attention_df, idxs))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 5: Causal Attention"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importlib.reload(model)\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "m5 = model.WSDModel(\n",
    "    tokens_vocab.size(),\n",
    "    y_vocab.size(),\n",
    "    D=D,\n",
    "    dropout_prob=dropout,\n",
    "    use_padding=True,\n",
    "    use_positional=True,\n",
    "    use_causal=True\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(m5.parameters(), lr=lr)\n",
    "\n",
    "losses5, train_acc5, val_acc5 = traineval.train(\n",
    "    m5, optimizer, sa_train_dataset, sa_dev_dataset, num_epochs=num_epochs, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Validation accuracy: {val_acc5[-1]:.3f}, Training accuracy:{train_acc5[-1]:.3f}\")\n",
    "assert val_acc5[\n",
    "           -1] >= 0.543, \"The last validation accuracy should be at least 0.543. Please check your implementation before you continue\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(nrows=2, figsize=(15, 6))\n",
    "\n",
    "axs[0].plot(losses5, '-', label='Train Loss')\n",
    "axs[0].legend()\n",
    "axs[1].plot(train_acc5, '-o', label='Train Acc')\n",
    "axs[1].plot(val_acc5, '-o', label='Val Acc')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "traineval.higlight_samples(m5, sa_dev_dataset, sample_size=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_df, attention_df = traineval.evaluate_verbose(m5, dev_dataset, iter_lim=100)\n",
    "\n",
    "idxs = np.where(eval_df['y_true'] != eval_df['y_pred'])\n",
    "idxs = list(idxs[0][:5])\n",
    "display(traineval.highlight(eval_df, attention_df, idxs))\n",
    "\n",
    "idxs = np.where(eval_df['query_token'] == 'left')\n",
    "display(traineval.highlight(eval_df, attention_df, idxs))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}